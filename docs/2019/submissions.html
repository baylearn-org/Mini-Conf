<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { /*

Copyright The Closure Library Authors.
SPDX-License-Identifier: Apache-2.0
*/
(function(){function e(g){this.t={};this.tick=function(h,k,f){this.t[h]=[void 0!=f?f:(new Date).getTime(),k];if(void 0==f)try{window.console.timeStamp("CSI/"+h)}catch(m){}};this.getStartTickTime=function(){return this.t.start[0]};this.tick("start",null,g)}var a;if(window.performance)var d=(a=window.performance.timing)&&a.responseStart;var l=0<d?new e(d):new e;window.jstiming={Timer:e,load:l};if(a){var b=a.navigationStart;0<b&&d>=b&&(window.jstiming.srt=d-b)}if(a){var c=window.jstiming.load;0<b&&d>=
b&&(c.tick("_wtsrt",void 0,b),c.tick("wtsrt_","_wtsrt",d),c.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),c&&0<b&&(c.tick("_tbnd",void 0,window.chrome.csi().startE),c.tick("tbnd_","_tbnd",b))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,c&&0<b&&(c.tick("_tbnd",void 0,window.external.startE),c.tick("tbnd_","_tbnd",b))),a&&(window.jstiming.pt=a)}catch(g){}})(); })()
</script>
<link rel="shortcut icon" type="image/x-icon" href="https://www.google.com/images/icons/product/sites-16.ico" />
<link rel="apple-touch-icon" href="https://ssl.gstatic.com/sites/p/c9c36f/system/app/images/apple-touch-icon.png" type="image/png" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { function d(a){return document.getElementById(a)}window.byId=d;function g(a){return a.replace(/^\s+|\s+$/g,"")}window.trim=g;var h=[],k=0;window.JOT_addListener=function(a,b,c){var f=new String(k++);a={eventName:a,handler:b,compId:c,key:f};h.push(a);return f};window.JOT_removeListenerByKey=function(a){for(var b=0;b<h.length;b++)if(h[b].key==a){h.splice(b,1);break}};window.JOT_removeAllListenersForName=function(a){for(var b=0;b<h.length;b++)h[b].eventName==a&&h.splice(b,1)};
window.JOT_postEvent=function(a,b,c){var f={eventName:a,eventSrc:b||{},payload:c||{}};if(window.JOT_fullyLoaded)for(b=h.length,c=0;c<b&&c<h.length;c++){var e=h[c];e&&e.eventName==a&&(f.listenerCompId=e.compId||"",(e="function"==typeof e.handler?e.handler:window[e.handler])&&e(f))}else window.JOT_delayedEvents.push({eventName:a,eventSrc:b,payload:c})};window.JOT_delayedEvents=[];window.JOT_fullyLoaded=!1;
window.JOT_formatRelativeToNow=function(a,b){a=((new Date).getTime()-a)/6E4;if(1440<=a||0>a)return null;var c=0;60<=a&&(a/=60,c=2);2<=a&&c++;return b?window.JOT_siteRelTimeStrs[c].replace("__duration__",Math.floor(a)):window.JOT_userRelTimeStrs[c].replace("__duration__",Math.floor(a))}; })()
</script>
<script>

  

  var breadcrumbs = [{"path":"/site/baylearn2019/submissions","deleted":false,"title":"Submissions","dir":"ltr"}];
  var JOT_clearDotPath = 'https://ssl.gstatic.com/sites/p/c9c36f/system/app/images/cleardot.gif';

  
  var JOT_userRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

  
  

  

  var webspace = {"gvizGstaticVersion":"current","enableAnalytics":false,"pageSharingId":"jotspot_page","codeembeds":{"outerIframeSrc":"https://www.gstatic.com/jotspot/embeds/code/0f08d42392f2000e7e3f3daf5b427a43/outer_iframe.html","innerIframeSrc":"https://825740216-jotspot-embeds.googleusercontent.com/code/8d87fa64604b2a11fae2ed06104c58d3/inner_iframe.html"},"enableUniversalAnalytics":false,"sharingPolicy":"OPENED","siteTitle":"BayLearn2019","experiments":{"enableSubpagesGadgetInTakeout":true,"overrideDisableDomainEditing":false,"DisableSiteEditingFeature__disable_site_editing":true,"disableDomainEditing":false},"jot2atari":{"eligibility":"INELIGIBLE"},"onepickUrl":"https://docs.google.com/picker","adsensePublisherId":null,"features":{"moreMobileStyleImprovements":null,"subscriptionDataMigrationInProgress":null,"plusBadge":false},"configProperties":{"disableSiteEditing":null},"isPublic":true,"newSitesBaseUrl":"https://sites.google.com","isConsumer":true,"serverFlags":{"jot2AtariLearnMoreUrl":"https://support.google.com/sites/answer/7035197"},"domainAnalyticsAccountId":"","plusPageId":"","signInUrl":"https://accounts.google.com/AccountChooser?continue\u003dhttps://sites.google.com/site/baylearn2019/submissions\u0026service\u003djotspot","analyticsAccountId":"","scottyUrl":"/_/upload","homePath":"/","siteNoticeUrlEnabled":null,"plusPageUrl":"","adsensePromoClickedOrSiteIneligible":true,"csiReportUri":"https://gg.google.com/csi","sharingId":"jotspot","termsUrl":"//www.google.com/intl/en/policies/terms/","gvizVersion":1,"editorResources":{"sitelayout":["https://ssl.gstatic.com/sites/p/c9c36f/system/app/css/sitelayouteditor.css"],"text":["https://ssl.gstatic.com/sites/p/c9c36f/system/js/codemirror.js","https://ssl.gstatic.com/sites/p/c9c36f/system/app/css/codemirror_css.css","https://ssl.gstatic.com/sites/p/c9c36f/system/js/trog_edit__en.js","https://ssl.gstatic.com/sites/p/c9c36f/system/app/css/trogedit.css","/site/baylearn2019/_/rsrc/1628148289000/system/app/css/editor.css","https://ssl.gstatic.com/sites/p/c9c36f/system/app/css/codeeditor.css","/site/baylearn2019/_/rsrc/1628148289000/system/app/css/camelot/editor-jfk.css"]},"sharingUrlPrefix":"/_/sharing","isAdsenseEnabled":true,"domain":"defaultdomain","baseUri":"/site/baylearn2019","name":"baylearn2019","siteTemplateId":false,"siteNoticeRevision":null,"siteNoticeUrlAddress":null,"siteNoticeMessage":null,"page":{"isRtlLocale":false,"canDeleteWebspace":null,"isPageDraft":null,"parentPath":null,"parentWuid":null,"siteLocale":"en","timeZone":"America/Los_Angeles","type":"text","title":"Submissions","locale":"en","wuid":"wuid:gx:3837babba40149be","revision":1,"path":"/submissions","isSiteRtlLocale":false,"pageInheritsPermissions":null,"name":"submissions","canChangePath":true,"state":"","properties":{},"bidiEnabled":false,"currentTemplate":{"path":"/system/app/pagetemplates/text","title":"Web Page"}},"canPublishScriptToAnyone":true,"user":{"keyboardShortcuts":true,"sessionIndex":"","guest_":true,"displayNameOrEmail":"guest","userName":"guest","uid":"","renderMobile":false,"domain":"","namespace":"","hasWriteAccess":false,"namespaceUser":false,"primaryEmail":"guest","hasAdminAccess":false,"isGoogleAdmin":false},"gadgets":{"baseUri":"/site/baylearn2019/system/app/pages/gadgets"}};
  webspace.page.breadcrumbs = breadcrumbs;

  
  var JOT_siteRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

</script>
<script type="text/javascript">
                window.jstiming.load.tick('scl');
              </script>
<meta name="title" content="Submissions - BayLearn2019" />
<meta itemprop="name" content="Submissions - BayLearn2019" />
<meta property="og:title" content="Submissions - BayLearn2019" />
<style type="text/css">
</style>
<link rel="stylesheet" type="text/css" href="https://ssl.gstatic.com/sites/p/c9c36f/system/app/themes/simplywhite/standard-css-simplywhite-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1628148289000/system/app/css/overlay%EF%B9%96cb=simplywhite19a%EF%B9%AA150goog-ws-nav-nosidenone30themedefaultcenter.css" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1628148289000/system/app/css/camelot/allthemes-view.css" />
<!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/site/baylearn2019/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->
<title>Submissions - BayLearn2019</title>
<meta itemprop="image" content="/site/baylearn2019/_/rsrc/1360758620844/config/customLogo.gif?revision=12" />
<meta property="og:image" content="/site/baylearn2019/_/rsrc/1360758620844/config/customLogo.gif?revision=12" />
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
</head>
<body xmlns="http://www.google.com/ns/jotspot" id="body" class=" en            ">
<div id="sites-page-toolbar" class="sites-header-divider">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-status" class="sites-status" style="display:none;"><div id="sites-notice" class="sites-notice" role="status" aria-live="assertive"> </div></div>
</div>
<div id="sites-chrome-everything-scrollbar">
<div id="sites-chrome-everything" class="">
<div id="sites-chrome-page-wrapper" style="direction: ltr">
<div id="sites-chrome-page-wrapper-inside">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-chrome-header-wrapper" style="height:auto;">
<table id="sites-chrome-header" class="sites-layout-hbox-centered" cellspacing="0" style="height:auto;">
<tr class="sites-header-primary-row" id="sites-chrome-userheader">
<td id="sites-header-title" class="sites-header-title-centered " role="banner"><div class="sites-header-cell-buffer-wrapper"><a href="index.html" id="sites-chrome-userheader-logo"><img id="logo-img-id" src="_/rsrc/1360758620844/config/customLogo.gif%EF%B9%96revision=12.jpeg" alt="BayLearn2019" class="sites-logo-centered  " /></a><h2></h2></div></td>
</tr>
<tr class="sites-header-secondary-row" id="sites-chrome-horizontal-nav">
<td colspan="2" id="sites-chrome-header-horizontal-nav-container" role="navigation">
<div class="sites-header-nav"><ul class="sites-header-nav-container-boxes"><li class="unselected"><a class="sites-navigation-link unselected" href="overview.html">Overview</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="venue.html">Venue</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="schedule.html">Schedule</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="keynotes.html">Keynotes</a></li><li class="current"><a class="sites-navigation-link current" href="submissions.html">Submissions</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="registration.html">Registration</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="sponsors.html">Sponsors</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="code-of-conduct.html">Code of Conduct</a></li><li class="unselected sites-header-nav-dropdown"><a class="sites-navigation-link unselected" href="previous.html">Previous</a><div class="sites-header-nav-dropdown-menu" style="display:none"><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="../baylearn2018/index.html">2018</a></div><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="../baylearn2017/index.html">2017</a></div><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="../baylearn2016/index.html">2016</a></div><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="../baylearn2015/index.html">2015</a></div><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="http://2014.baylearn.org">2014</a></div><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="http://2013.baylearn.org">2013</a></div><div class="sites-header-nav-dropdown-menuitem unselected"><a class="sites-navigation-link unselected" href="http://2012.baylearn.org">2012</a></div></div></li></ul><div style="clear: both;"></div></div>
</td>
</tr>
</table>
</div>
<div id="sites-chrome-main-wrapper">
<div id="sites-chrome-main-wrapper-inside">
<table id="sites-chrome-main" class="sites-layout-hbox" cellspacing="0" cellpadding="{scmCellpadding}" border="0">
<tr>
<td id="sites-chrome-sidebar-left" class="sites-layout-sidebar-left" style="display: none; width: 150px">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_2bd" class="sites-embed" role="navigation"><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList" class="has-expander"><li class="topLevel nav-first parent " wuid="gx:1fa6fd4847a66c16"><div dir="ltr" style="padding-left: 0px;"><div class="expander"></div><a href="overview.html" jotId="wuid:gx:1fa6fd4847a66c16" class="sites-navigation-link topLevel">Overview</a></div><ul role="navigation" class="has-expander"><li class=""><div dir="rtl" style="padding-left: 38px;"><a href="overview/call-for-abstracts.html" jotId="wuid:gx:110a09e310bf9931" class="sites-navigation-link">.</a></div></li><li class=""><div dir="ltr" style="padding-left: 38px;"><a href="overview/call-for-abstracts-2015.html" jotId="wuid:gx:43fda008666fbeb2" class="sites-navigation-link">Call For Abstracts 2015</a></div></li><li class=""><div dir="ltr" style="padding-left: 38px;"><a href="overview/reviewers.html" jotId="wuid:gx:3b73470ead3df56d" class="sites-navigation-link">Reviewers</a></div></li></ul></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="code-of-conduct.html" jotId="wuid:gx:4fa49a70b7766d0" class="sites-navigation-link topLevel">Code of Conduct</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="keynotes.html" jotId="wuid:gx:2cd522c2146e4655" class="sites-navigation-link topLevel">Keynotes</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="overview2016.html" jotId="wuid:gx:2561bffb7f16cd83" class="sites-navigation-link topLevel">overview2016</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="previous.html" jotId="wuid:gx:642c186e0c9f061c" class="sites-navigation-link topLevel">Previous</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="privacypolicy.html" jotId="wuid:gx:75e5641ec54d0089" class="sites-navigation-link topLevel">PrivacyPolicy</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="registration.html" jotId="wuid:gx:694033be15ae199a" class="sites-navigation-link topLevel">Registration</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="schedule.html" jotId="wuid:gx:62d17b9972aa0397" class="sites-navigation-link topLevel">Schedule</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="sponsors.html" jotId="wuid:gx:584b850188c37736" class="sites-navigation-link topLevel">Sponsors</a></div></li><li class="topLevel "><div class="current-bg" jotId="wuid:gx:3837babba40149be" dir="ltr" style="padding-left: 19px;">Submissions</div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="venue.html" jotId="wuid:gx:735659fdc82e7442" class="sites-navigation-link topLevel">Venue</a></div></li><li class="topLevel "><div dir="ltr" style="padding-left: 19px;"><a href="system/app/pages/sitemap/hierarchy.html" jotId="wuid:gx:38ea747d7de47596" class="sites-navigation-link topLevel">Sitemap</a></div></li></ul></div></div>
</td>
<td id="sites-canvas-wrapper">
<div id="sites-canvas" role="main">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
</div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="left">
<span id="sites-page-title" dir="ltr" tabindex="-1" style="outline: none">Submissions</span>
</h3>
<div id="sites-canvas-main" class="sites-canvas-main">
<div id="sites-canvas-main-content">
<table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0" class="sites-layout-name-one-column sites-layout-hbox"><tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr"><div><div><h2><a name="TOC-Accepted-Submissions-zip-archive-"></a>Accepted Submissions [<a href="https://sites.google.com/site/baylearn2019/submissions/baylearn-2019-accepted-submissions.zip?attredirects=0">zip archive</a>]<br /></h2><div>Congratulations to all authors. We have total 72 accepted submissions this year. The submissions, if permitted by the authors, are available to download.<br /></div><div><h3><a name="TOC-ORAL-PRESENTATIONS:"></a>ORAL PRESENTATIONS:<br /></h3></div><div><table border="1" bordercolor="#888" cellspacing="0" style="border-collapse:collapse;border-color:rgb(136,136,136);border-width:1px"><tbody><tr><td style="text-align:center;width:414px;height:19px"> <font size="3"><b>Title</b><span>    </span></font></td><td style="text-align:center;width:914px;height:19px"> <b><font size="3">Abstract</font></b></td><td style="text-align:center;width:314px;height:19px"> <b><font size="3">Authors</font></b></td></tr><tr><td style="width:414px;height:112px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings</span></td><td style="width:914px;height:112px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">For autonomous vehicles (AVs) to behave appropriately on roads populated by human-driven vehicles, they must be able to reason about the uncertain intentions and decisions of other drivers from rich perceptual information. Towards these capabilities, we present a probabilistic forecasting model of future interactions of multiple agents. We perform both standard forecasting and conditional forecasting with respect to the AV's goals. Conditional forecasting reasons about how all agents will likely respond to specific decisions of a controlled agent. We train our model on real and simulated data to forecast vehicle trajectories given past positions and LIDAR. Our evaluation shows that our model is substantially more accurate in multi-agent driving scenarios compared to existing state-of-the-art. Beyond its general ability to perform conditional forecasting queries, we show that our model's predictions of all agents improve when conditioned on knowledge of the AV's intentions, further illustrating its capability to model agent interactions.</span></td><td style="width:314px;height:112px"> Nicholas Rhinehart (CMU)*; <span style="color:rgb(51,51,51);font-size:10pt;font-family:Arial">Rowan McAllister (UC Berkeley); </span><span style="color:rgb(51,51,51);font-size:10pt;font-family:Arial">Kris Kitani (CMU); Sergey Levine (UC Berkeley)</span></td></tr><tr><td style="width:414px;height:96px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">A/B Testing in Dense Large-Scale Networks: Design and Inference</span></td><td style="width:914px;height:96px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Design of experiments and estimation of treatment effects in large-scale networks, in the presence of strong interference, is a challenging and important problem. Most existing methods' performance deteriorates as the density of the network increases. In this paper, we present a novel strategy for accurately estimating the causal effects of a class of treatments in a dense large-scale network. First, we design an approximate randomized controlled experiment, by solving an optimization problem to allocate treatments that mimic the competition effect. Then we apply an importance sampling adjustment to correct for the design bias in estimating treatment effects from experimental data. We provide theoretical guarantees, verify robustness in a simulation study, and validate the usefulness of our procedure in a real-world experiment.</span></td><td style="width:314px;height:96px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Preetam Nandy (LinkedIn Corporation)*; Kinjal Basu (LinkedIn Corporation); Shaunak Chatterjee (LinkedIn); Ye Tu (LinkedIn Corporation)</span></td></tr><tr><td style="width:414px;height:127px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss</span></td><td style="width:914px;height:127px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Deep learning algorithms can fare poorly when the training dataset suffers from heavy class-imbalance but the testing criterion requires good generalization on less frequent classes. We design two novel methods to improve performance in such scenarios. First, we propose a theoretically-principled label-distribution-aware margin (LDAM) loss motivated by minimizing a margin-based generalization bound. This loss replaces the standard cross-entropy objective during training and can be applied with prior strategies for training with class-imbalance such as re-weighting or re-sampling. Second, we propose a simple, yet effective, training schedule that defers re-weighting until after the initial stage, allowing the model to learn an initial representation while avoiding some of the complications associated with re-weighting or re-sampling. We test our methods on several benchmark vision tasks including the real-world imbalanced dataset iNaturalist 2018. Our experiments show that either of these methods alone can already improve over existing techniques and their combination achieves even better performance gains.</span></td><td style="width:314px;height:127px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Kaidi Cao (Stanford University)*; Colin Wei (Stanford University); Adrien Gaidon (Toyota Research Institute); Nikos Arechiga (Toyota Research Institute); Tengyu Ma (Stanford)</span></td></tr><tr><td style="width:414px;height:80px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Gradient Boosted Decision Tree Neural Network</span></td><td style="width:914px;height:80px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">In this paper we propose a method to build GBDT equivalent models using neural networks. We first illustrate how to convert a learned ensemble of decision trees to a single neural network with one hidden unit and an input transformation. We then relax some properties of this network such as thresholds and activation functions to train approximately equivalent decision tree ensemble. The final model, GBDT-NN, is surprisingly simple. It is a fully connected two layers neural network where the input is quantized and one-hot encoded. Experiments on large and small datasets show this simple method can achieve performance similar to GBDT models.</span></td><td style="width:314px;height:80px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Mohammad Saberian (Netflix)*; Pablo Delgado (Netflix); Yves Raimond (Netflix) <br /></span></td></tr><tr><td style="width:414px;height:127px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies</span></td><td style="width:914px;height:127px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Does knowing that the world is 3D help in delivering a package? More generally, how much does having visual priors about the world assist in learning to perform downstream motor tasks?  We study this question by integrating a generic perceptual skill set (e.g. a distance estimator, an edge detector, etc.) within a reinforcement learning framework. This skill set (hereafter mid-level perception) provides the policy with a more processed state of the world compared to raw images.  We find that using a mid-level perception confers significant advantages over training end-to-end from scratch (i.e. not leveraging priors) in navigation-oriented tasks. Agents are able to generalize to situations where the from-scratch approach fails and training becomes significantly more sample efficient. However, we show that realizing these gains requires careful selection of the mid-level perceptual skills. Therefore, we refine our findings into an efficient max-coverage feature set that can be adopted in lieu of raw images. We perform our study in completely separate buildings for training and testing and compare against state-of-the-art feature learning methods and visually blind baseline policies.</span></td><td style="width:314px;height:127px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Alexander Sax (University of California, Berkeley)*; Bradley Emi (Stanford University); Amir Zamir (Stanford, UC Berkeley); Jitendra Malik (University of California at Berkley); Leonidas Guibas (Stanford University); Silvio Savarese (Stanford University); Jeffrey O Zhang (</span><span style="font-size:10pt;font-family:Arial;font-style:normal"><span style="font-size:10pt;font-family:Arial;font-style:normal">University of California, Berkeley</span>)<br /></span></td></tr><tr><td style="width:414px;height:64px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">State-of-the-art Speech Recognition Using Multi-Stream Self-Attention</span></td><td style="width:914px;height:64px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Self-attention has been a huge success for many downstream tasks in NLP, which led to exploration of applying self-attention to speech problems as well. The efficacy of self-attention in speech applications, however, seems not fully blown yet since it is challenging to handle highly correlated speech frames in the context of self-attention. In this paper we propose a new model architecture for self-attention, namely multi-stream self-attention, to address the issue thus make the self-attention mechanism more effective for speech recognition.</span></td><td style="width:314px;height:64px"> <span style="font-size:10pt;font-family:Arial;font-style:normal">Kyu Han (ASAPP, Inc.)*; Ramon Prieto (ASAPP Inc.); Tao Ma (ASAPP Inc.)</span></td></tr></tbody></table></div><div><br /></div><div><h3><a name="TOC-POSTERS:"></a>POSTERS:</h3><div><table border="1" cellpadding="0" cellspacing="0" dir="ltr" style="table-layout:fixed;font-size:10pt;font-family:Arial;border-collapse:collapse;border:medium none"><colgroup><col width="693" /><col width="3809" /></colgroup><tbody><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;font-weight:bold;width:306px;height:16px">Paper Title</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;font-weight:bold;width:1331px;height:16px">Authors</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">Computer games or the trajectories of physics? Discovering the Carnot cycle using reinforcement learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Stephen Whitelam (Lawrence Berkeley National Lab)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Coordinated Exploration via Intrinsic Rewards for Multi-Agent Reinforcement Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Shariq Iqbal (University of Southern California)*; Fei Sha (Google Research)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Collaborative Evolutionary Reinforcement Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Shauharda Khadka (Intel AI Lab); Somdeb Majumdar (Intel AI Lab)*; Santiago Miret (Intel AI Lab); Evren Tumer (Intel Corporation)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Topic Augmented Generator for Abstractive Summarization</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Melissa Ailem (University of Southern California)*; Bowen Zhang (University of Southern California); Fei Sha (Google Research)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Image Captioning: Transforming Objects into Words</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Simao Herdade (Yahoo Research)*; Kofi A Boakye (Yahoo Research ); Armin Kappeler (Yahoo Research); Joao V. B. Soares (Yahoo Research)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Cross-View Policy Learning for Street Navigation</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Ang Li (DeepMind, Mountain View)*; Huiyi Hu (Google); Piotr Mirowski (DeepMind); Mehrdad Farajtabar (DeepMind)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Layout-induced Video Representation for Recognizing Agent-in-Place Actions</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Ruichi Yu (Waymo LLC.)*; Hongcheng Wang (Comcast); Ang Li (DeepMind, Mountain View); Jingxiao Zheng (University of Maryland, College Park); Vlad I Morariu (Adobe Research); Larry Davis (University of Maryland)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">Uncertainty Modeling of Contextual-Connection between Tracklets for Unconstrained Video-based Face Recognition</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Jingxiao Zheng (University of Maryland, College Park)*; Ruichi Yu (Waymo LLC.); Jun-Cheng Chen (University of Maryland); Boyu Lu ("University of Maryland, College Park"); Carlos Castillo (University of Maryland); Rama Chellappa (University of Maryland)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Neural Assistant: Joint Action Prediction, Response Generation, and Latent Knowledge Reasoning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Arvind Neelakantan (Google Inc)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Guan-Lin Chao (Carnegie Mellon University)*; Ian Lane (Carnegie Mellon University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">Improved Knowledge Distillation via Teacher Assistant: Bridging the Gap Between Student and Teacher</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Seyed Iman Mirzadeh (Washington State University); Mehrdad Farajtabar (DeepMind)*; Ang Li (DeepMind, Mountain View); Hassan Ghasemzadeh (Washington State University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Chen Huang (Apple)*; Shuangfei Zhai (Apple); Walter Talbott (Apple); Miguel Angel Bautista Martin (Apple Inc.); Shih-Yu Sun (Apple); Carlos Guestrin (Apple); Josh Susskind (Apple)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">An Improved Triplet Loss Formulation</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Walter Talbott (Apple)*; Chen Huang (Apple); Shih-Yu Sun (Apple); Josh Susskind (Apple)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Striving for Simplicity in Off-policy Deep Reinforcement Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Rishabh Agarwal (Google Research, Brain Team)*; Dale Schuurmans (Google / University of Alberta); Mohammad Norouzi (Google Brain)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">Rapid gamma-ray burst localization aboard the All-Sky-Astrogam satellite using a 3D convolutional neural network</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Ruoxi Shang (UC Berkeley)*; Andreas Zoglauer (University of California, Berkeley)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Causal Confusion in Imitation Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Pim de Haan (University of Amsterdam)*; Dinesh Jayaraman (UC Berkeley); Sergey Levine (UC Berkeley)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Nir Levine (Deepmind)*; Yinlam Chow (Google AI); Rui Shu (Stanford University); Mohammad Ghavamzadeh (Facebook AI Research); Ang Li (DeepMind, Mountain View); Hung H Bui (VinAI Research)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Robust Reinforcement Learning for Continuous Control with Model Misspecification</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Nir Levine (Deepmind)*; Daniel Mankowitz (DeepMind); Rae Jeong (DeepMind); Abbas Abdolmaleki (Google DeepMind); Jost Tobias Springenberg (DeepMind); Timothy Arthur Mann (); Todd Hester (DeepMind); Martin Riedmiller (DeepMind)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Multiagent Evolutionary Reinforcement Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Shauharda Khadka (Intel AI Lab); Somdeb Majumdar (Intel AI Lab)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Bridging the Gap for Tokenizer-Free Language Models</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Dokook Choe (Google)*; Rami Al-Rfou' (rmyeid@google.com); Mandy Guo (xyguo@google.com); Heeyoung Lee (hylee@google.com); Noah Constant (nconstant@google.com)<br /></td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">The Trajectron: Probabilistic Multi-Agent Trajectory Modeling with Dynamic Spatiotemporal Graphs</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Boris Ivanovic (Stanford University)*; Marco Pavone (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">A Fourier Perspective on Model Robustness in Computer Vision</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Dong Yin (University of California, Berkeley)*; Raphael Gontijo Lopes (Google Brain); Jonathon Shlens (Google); Ekin D Cubuk (Google Brain); Justin Gilmer (Google Brain)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">When to Trust Your Model: Model-Based Policy Optimization</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Michael Janner (UC Berkeley)*; Justin Fu (UC Berkeley); Marvin Zhang (UC Berkeley); Sergey Levine (UC Berkeley)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Compressing Gradient Optimizers via Count-Sketches</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Ryan D Spring (Rice University)*; Anshumali Shrivastava (Rice University); Anastasios Kyrillidis (Rice University ); Vijai Mohan (www.amazon.com)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">The invisible hand of fractals and scaling in recommendations</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Francois W Belletti (Google)*; Minmin Chen (Google); Ed Chi (Google); Yi-fan Chen (Google); Nic Mayoraz (Google); Tayo Oguntebi (Google LLC); John Anderson (Google)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Hydroclimate and Snowpack Modeling with cGANs</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Adrian Albert (MIT)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Multitask Learning for Recommendation Systems</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Zhe Zhao (Google Brain)*; Lichan Hong (Google); Jilin Chen (Google Brain); Xinyang Yi (Google); Maheswaran Sathiamoorthy (Google); Li Wei (Google); Ruoxi Wang (Google); Ji Yang (Google); Zhiyuan Cheng (Google); Ed Chi (Google)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">Creating xBD: A Dataset for Assessing Building Damage from Satellite Imagery</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Ritwik Gupta (Carnegie Mellon University Software Engineering Institute)*; Bryce Goodman (Defense Innovation Unit); Nirav Patel (Defense Innovation Unit); Richard Hosfelt (Carnegie Mellon University Software Engineering Institute); Sandra Sajeev (Carnegie Mellon University Software Engineering Institute); Eric Heim (Carnegie Mellon University Software Engineering Institute); Jigar Doshi (CrowdAI, Inc.); Keane Lucas (Joint Artificial Intelligence Center); Howie Choset (Carnegie Mellon University); Matthew Gaston (Carnegie Mellon University Software Engineering Institute)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">REPLAB: A Reproducible Low-Cost Arm Benchmark Platform for Robotic Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Brian Yang (UC Berkeley); Jesse Zhang (UC Berkeley); Vitchyr H Pong (UC Berkeley); Sergey Levine (UC Berkeley); Dinesh Jayaraman (UC Berkeley)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Justin Fu (UC Berkeley)*; Aviral Kumar (UC Berkeley)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Near Real-time Engagement Optimization of Mobile Notifications</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Yiping Yuan (LinkedIn)*; Padmini Jaikumar (LINKEDIN CORPORATION); Yan Gao (LINKEDIN CORPORATION); Ajith Muralidharan (LINKEDIN CORPORATION)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Distributed Learning of Latent Representation Social Network Graph Entities</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Yiou Xiao (LinkedIn)*; Yafei Wang (LinkedIn); Matthew Walker (Linkedin)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Understanding Posterior Collapse in Variational Autoencoders</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">James R Lucas (University of Toronto)*; Mohammad Norouzi (Google Brain); George Tucker (Google Brain); Roger B Grosse (University of Toronto)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:64px">Zero-Shot Transfer Learning for Query-Item Cold Start in Search Retrieval and Recommendations</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:64px">Tao Wu (iotao@google.com)*; Ellie Ka-In Chio (echio@google.com); Heng-Tze Cheng (hengtze@google.com); Yu Du (cosmodu@google.com); Ritesh Agarwal (riteshag@google.com); Dima Kuzmin (dimakuzmin@google.com); Steffen Rendle (srendle@google.com); Li Zhang (liqzhang@google.com); John Anderson (janders@google.com); Sarvjeet Singh (sarvjeet@google.com); Tushar Chandra (tushar@google.com); Ed H. Chi (edchi@google.com); Wen Li (lwen@google.com); Ankit Kumar (ankitkr@google.com); Xiang Ma (xiangma@google.com); Alex Soares (alexsoares@google.com); Nitin Jindal (nitinjindal@google.com); Pei Cao (pei@google.com)<br /></td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Neural Modeling for Large Corpus Item Recommendations</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Xinyang Yi (Google)*; Ji Yang (Google); Zhiyuan Cheng (Google); Zhe Zhao (Google Brain); Lichan Hong (Google); Ed Chi (Google)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Collapsed amortized variational inference for switching nonlinear dynamical systems</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Zhe Dong (Google)*;  Bryan Seybold (Google); Kevin Murphy (Google); Hung H Bui (VinAI Research)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Semantic Coherence Analysis</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px"><div><span style="color:rgb(51,51,51);font-family:Arial;font-size:13.333333015441895px">Moussa Doumbouya (Work done while at Apple Inc.)*; Skyler Seto (Work done while at Apple Inc.); Enguerrand Horel (Work done while at Apple Inc); Luca Zappella (Apple Inc.); Xavier Suau Cuadros (Apple Inc.); Nicholas Apostoloff (Apple Inc.)</span></div></td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Evolving Losses for Video Representation Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">AJ Piergiovanni (Indiana University)*; Anelia Angelova (Google); Michael S Ryoo (Google Brain; Indiana University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Learning an Adaptive Learning Rate Schedule</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Zhen Xu (Google)*; Andrew  M Dai (Google Brain); Jonas Kemp (Google); Luke Metz (Google Brain)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Learning Differentiable Grammars for Videos</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">AJ Piergiovanni (Indiana University)*; Anelia Angelova (Google); Michael S Ryoo (Google Brain; Indiana University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">EvaNet: A Family of Diverse, Fast and Accurate Video Architectures</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">AJ Piergiovanni (Indiana University); Anelia Angelova (Google)*; Alexander Toshev (Google); Michael S Ryoo (Google Brain; Indiana University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">A Programming System and Automation Libraries for DNN Model Compression</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Vinu Joseph (UNIVERSITY OF UTAH)*; Saurav Muralidharan (NVIDIA); Animesh Garg (Stanford, Nvidia); Ganesh Gopalakrishnan (University of Utah); Michael Garland (NVIDIA)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Energy-Inspired Models</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Dieterich Lawson (NYU); George Tucker (Google Brain)*; Bo Dai (Google Brain); Rajesh Ranganath (New York University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Unlabeled Data Improves Adversarial Robustness</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Yair Carmon (Stanford)*; Aditi Raghunathan (Stanford University); Ludwig Schmidt (UC Berkeley); Percy Liang (Stanford University); John Duchi (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Skew-Fit: State-Covering Self-Supervised Reinforcement Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Murtaza Dalal (UC Berkeley)*; Vitchyr H Pong (UC Berkeley); Steven Lin (UC Berkeley); Ashvin V Nair (UC Berkeley); Shikhar Bahl (UC Berkeley); Sergey Levine (UC Berkeley)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Randomized Bandit Exploration Revisited</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Branislav Kveton (Google Research)*; Csaba Szepesvari (DeepMind/University of Alberta); Mohammad Ghavamzadeh (Facebook AI Research); Craig Boutilier (Google Research)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">COTA: Improving the customer support experience using Deep Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Aditya V Guglani (Uber Technologies, Inc.)*; Huaixiu Zheng (Uber Technologies); Hugh Williams (Uber); Arun Bodapati (Uber Technologies, Inc.)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Personalization and Optimization of Decision Parameters via Heterogenous Causal Effects</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Ye Tu (LinkedIn Corporation)*; Kinjal Basu (LinkedIn Corporation); Shaunak Chatterjee (Linkedin); Jinyun Yan (Linkedin); Birjodh Tiwana (Linkedin)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Modeling Local Geometric Structure of 3D Point Clouds using Geo-CNN</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Shiyi Lan (University of Maryland)*; Ruichi Yu (Waymo LLC.); Gang Yu (Megvii Inc); Larry Davis (University of Maryland)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Variance Reduction for Matrix Games</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Yair Carmon (Stanford)*; Yujia Jin (Stanford University); Aaron Sidford (Stanford); Kevin Tian (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Curvature: A Scalable Deep Learning Architecture for Real-Time Back-Scatter EM Sensing</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Luca Rigazio (Totemic)*; Samuel Joseph (Totemic)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Online Meta-Reinforcement Learning via Gaussian Process Temporal Difference Learning</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Roman Engeler (ETH Zurich); James Harrison (Stanford University)*; Apoorva Sharma (Stanford University); Emma Brunskill (Stanford University); Marco Pavone (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Stand-Alone Self-Attention for Vision Models</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Prajit Ramachandran (Google)*; Niki Parmar (Google); Ashish Vaswani (Google Brain); Irwan Bello (Google); Anselm Levskaya (Google); Jonathon Shlens (Google)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Practical Thompson Sampling for Constrained Contextual Bandit Problems</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Samuel Daulton (Facebook)*; Shaun Singh (Facebook); Drew Dimmery (Facebook); Eytan Bakshy (Facebook)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">InfoCNF: An Efficient Conditional Continuous Normalizing Flow with Adaptive Solvers</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Tan Minh Nguyen (Rice University)*; Animesh Garg (Stanford, Nvidia); Richard Baraniuk (Rice University); Animashree Anandkumar (Caltech)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:48px">Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:48px">Yaniv Ovadia (Google Inc); Emily Fertig (Google); Jie Ren (Google Research); Zachary Nado (Google Inc.); D Sculley (Google); Sebastian Nowozin (Google Research); Joshua V Dillon (Google); Balaji Lakshminarayanan (Google DeepMind)*; Jasper Snoek (Google Brain)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Do Deep Generative Models Know What They Don't Know?</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Eric Nalisnick (DeepMind); Akihiro Matsukawa (DeepMind); Yee Whye Teh (DeepMind); Dilan Gorur (); Balaji Lakshminarayanan (Google DeepMind)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">Social Skill Validation at LinkedIn</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Xiao Yan (LinkedIn)*; Jaewon Yang (LINKEDIN CORPORATION); Qi He (LinkedIn)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Off-Policy Policy Gradient with StationaryDistribution Correction</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Yao Liu (Stanford University)*; Alekh Agarwal (Microsoft); Adith Swaminathan (Microsoft Research); Emma Brunskill (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Better predictions with contextual pretraining over clinical notes</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Jonas Kemp (Google)*; Alvin Rajkomar (Google); Andrew  M Dai (Google Brain)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Ultra Fast Medoid Identification via Correlated Sequential Halving</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Tavor Z Baharav (Stanford University)*; David Tse (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">PEARL: Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Kate Rakelly (UC Berkeley)*; Aurick Zhou (UC Berkeley); Deirdre Quillen (UC Berkeley); Chelsea Finn (UC Berkeley); Sergey Levine (UC Berkeley)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">The Optimal Model Design Problem</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Pierre-Luc Bacon (Stanford University)*; Emma Brunskill (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Which Tasks Should Be Learned Together in Multi-task Learning?</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Trevor S Standley (Stanford University)*; Amir Zamir (Stanford, UC Berkeley); Dawn Chen (Google); Leonidas Guibas (Stanford University); Jitendra Malik (University of California at Berkley); Silvio Savarese (Stanford University)</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:32px">Do deep neural networks train by learning shallowlearnable examples first?</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:32px">Karttikeya Mangalam (Stanford University)*</td></tr><tr style="height:21px"><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:306px;height:16px">No More Mode Collapse</td><td style="overflow:hidden;padding:2px 3px;vertical-align:bottom;width:1331px;height:16px">Ke Li (UC Berkeley)*; Jitendra Malik (University of California at Berkley)</td></tr></tbody></table></div></div><h2><a name="TOC-1"></a><br /></h2><h2><a name="TOC-Call-for-Submissions"></a>Call-for-Submissions</h2></div><div><br /></div><div>Please <a href="https://cmt3.research.microsoft.com/BAYLEARN2019" rel="nofollow">submit your proposals via CMT</a> in the form of an abstract as a 2-page pdf in the <a href="https://neurips.cc/Conferences/2019/PaperInformation/StyleFiles" rel="nofollow">NeurIPS Style</a> by 11:59:59PM PDT, <span style="color:rgb(0,0,0);font-family:Arial;font-size:13.333333015441895px">June 18th, 2019.</span>  References can be included in a third page. </div><div>Note: Submissions are not blind-reviewed, thus please include authors' names and affiliations in the submissions.</div><div><br /></div><div><span style="white-space:pre-wrap;color:rgb(0,0,0);font-family:Arial;font-size:13.3333px">Acceptable material includes work which has already been submitted or published, preliminary results and controversial findings. </span></div><div><font color="#000000" face="Arial"><span style="white-space:pre-wrap">We do not intend to publish paper proceedings, </span></font><span style="font-family:arial,sans-serif;font-size:small;white-space:pre-wrap;color:rgb(0,0,0)">only abstracts will be shared through an online repository. Our primary goal is to foster discussion!</span></div></div><div><font color="#000000" face="Arial"><span style="white-space:pre-wrap"><br /></span></font></div><div>For examples of abstracts that have been selected in the past, please see the <a href="../baylearn2018/schedule.html">schedule of talks from BayLearn 2018</a>. This page has videos of the talks and links to PDFs of the abstracts are provided for each of the selected talks.</div></div></td></tr></tbody></table>
</div> 
</div> 
<div id="sites-canvas-bottom-panel">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
<div id="sites-attachments-container">
</div>
</div>
</div> 
</td> 
</tr>
</table> 
</div> 
</div> 
<div id="sites-chrome-footer-wrapper">
<div id="sites-chrome-footer-wrapper-inside">
<div id="sites-chrome-footer">
</div>
</div>
</div>
</div> 
</div> 
<div id="sites-chrome-adminfooter-container">
<div xmlns="http://www.w3.org/1999/xhtml" class="sites-adminfooter" role="navigation"><p><a class="sites-system-link" href="system/app/pages/reportAbuse.html" target="_blank">Report Abuse</a><span aria-hidden="true">|</span><span class="sites-system-link">Powered By</span> <b class="powered-by"><a href="http://sites.google.com/site">Google Sites</a></b></p></div>
</div>
</div> 
</div> 
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('sjl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" src="https://ssl.gstatic.com/sites/p/c9c36f/system/js/jot_min_view__en.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('jl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
      gsites.HoverPopupMenu.createSiteDropdownMenus('sites-header-nav-dropdown', false);
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("2bd", "Navigation", true);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_2bd');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
  setTimeout(function() {
    var fingerprint = gsites.date.TimeZone.getFingerprint([1109635200000, 1128902400000, 1130657000000, 1143333000000, 1143806400000, 1145000000000, 1146380000000, 1152489600000, 1159800000000, 1159500000000, 1162095000000, 1162075000000, 1162105500000]);
    gsites.Xhr.send('https://sites.google.com/site/baylearn2019/_/tz', null, null, 'GET', null, null, { afjstz: fingerprint });
  }, 500);
</script>
<script xmlns="http://www.w3.org/1999/xhtml">
                    window.onload = function() {
                      if (false) {
                        JOT_setMobilePreview();
                      }
                      var loadTimer = window.jstiming.load;
                      loadTimer.tick("ol");
                      loadTimer["name"] = "load," + webspace.page.type + ",user_page";
                      window.jstiming.report(loadTimer, {}, 'https://gg.google.com/csi');
                    }
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
        JOT_insertAnalyticsCode(false,
            false);
      </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    var maestroRunner = new gsites.pages.view.SitesMaestroRunner(
        webspace, "en");
    maestroRunner.initListeners();
    maestroRunner.installEditRender();
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
  //<![CDATA[
    // Decorate any fastUI buttons on the page with a class of 'goog-button'.
    if (webspace.user.hasWriteAccess) {
      JOT_decorateButtons();
    }

    // Fires delayed events.
    (function() {
      JOT_fullyLoaded = true;
      var delayedEvents = JOT_delayedEvents;
      for (var x = 0; x < delayedEvents.length; x++) {
        var event = delayedEvents[x];
        JOT_postEvent(event.eventName, event.eventSrc, event.payload);
      }
      JOT_delayedEvents = null;
      JOT_postEvent('pageLoaded');
    })();
  //]]>
</script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    JOT_postEvent('decorateGvizCharts');
  </script>
<script type="text/javascript">
          JOT_setupPostRenderingManager();
        </script>
<script type="text/javascript">
          JOT_postEvent('renderPlus', null, 'sites-chrome-main');
        </script>
<script type="text/javascript">
          sites.codeembed.init();
        </script>
<div id="server-timer-div" style="display:none"> </div>
<script type="text/javascript">
          window.jstiming.load.tick('render');
          JOT_postEvent('usercontentrendered', this);
        </script>
</body>
</html>
