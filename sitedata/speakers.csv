UID,image,title,speaker,institution,talk_title,talk_abstract,bio,session,"homepage"
1,"static/images/speakers/samy_apple_2021.jpeg","","Dr. Samy Bengio","Apple","Recent Advances in Representation Learning","Deep learning has made a lot of progress in the past decade which yielded impressive results transforming applications such as speech recognition or machine translation, but much more needs to be done in order to build and understand better representation learning approaches in terms of fairness, efficiency and robustness. In this presentation, I will go over a set of recent research work from our Machine Learning Research team at Apple towards better understanding important aspects of representation learning.","Senior Director, AI and Machine Learning Research","","https://bengio.abracadoudou.com/"
2,"static/images/speakers/rediet.jpg","","Dr. Rediet Abebe","Harvard Society of Fellows","Algorithms on the Bench: Evaluating Validity of Machine Learning Systems in the Public Sphere","Abstract TBD","Junior Fellow","",""
3,"static/images/speakers/zoubin.jpg","","Dr. Zoubin Ghahramani","Google and University of Cambridge","Recent Advances in AI from Google Research","While the last decade of research in AI and machine learning has produced spectacular advances and practical impact, in the last few months progress seems to have accelerated driven by very large models. I'll describe some of the trends helping this and outline work on several recent advances from Google Research. My tour will include text-to-image generation models (Imagen and Parti), open-ended dialog systems (LaMDA), multi-task language models (PaLM), language-driven robotics (PaLM-SayCan) and foundational work on helping these models integrate into useful human-centric applications in a responsible way.","VP Research, Google, and Professor, University of Cambridge","",""
4,"static/images/speakers/trevor.jpg","","Dr. Trevor Darrell","UC Berkeley","Unsupervised, Adaptive, and Advisable Visual Learning","Unsupervised and cross-modal methods are rapidly overtaking supervised techniques as the dominant paradigm for visual learning.  Models based on reconstruction, masking, and denoising have demonstrated ability to generalize from few examples, allow interpretable interaction, and learn from few or no labeled examples. I'll survey recent advances at Berkeley developing such models for visual pretraining of robotic agents, learning visual analogies, adapting to out-of-distribution data, and learning social gestures, and will speculate on future unified models as time permits.","Professor, UC Berkeley","","https://people.eecs.berkeley.edu/~trevor/"
