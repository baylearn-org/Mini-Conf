UID,image,title,speaker,institution,talk_title,talk_abstract,bio,session,"homepage"
1,"static/images/speakers/FeiFei Picture small.jpg","Sequoia Capital Professor, Co-Director of the Stanford Institute for Human-Centered Artificial Intelligence (HAI)","Prof. Fei-Fei Li","Stanford HAI","Talk Title - To be added","Talk Abstract - To be added","Speaker Bio - to be added","session","homepage"
2,static/images/speakers/headshot_salehi.jpg,"Assistant professor","Prof. Niloufar Salehi","School of Information at UC, Berkeley",Designing Reliable Human-AI Interactions,"How can users trust an AI system that fails in unpredictable ways? Machine learning models, while powerful, can produce unpredictable results. This uncertainty becomes even more pronounced in areas where verification is challenging, such as in machine translation or probabilistic genotyping. Providing users with guidance on when to rely on a system is challenging because models can create a wide range of outputs (e.g. text), error boundaries are highly stochastic, and automated explanations themselves may be incorrect. In this talk, I will discuss approaches to improving the reliability of ML-based systems by designing actionable strategies for a user to gauge reliability and recover from potential errors. At a higher level, I will share perspectives from the field of HCI on designing reliable AI systems by centering user needs and context of use.","Niloufar Salehi is an assistant professor in the School of Information at UC, Berkeley and faculty member of Berkeley AI Research (BAIR). She studies human-computer interaction, with her research spanning education to healthcare to restorative justice. Her research interests are in social computing, human-centered AI, and more broadly, human-computer interaction (HCI). Her work has been published and received awards in premier venues including ACM CHI and CSCW and has been covered in Venture Beat, Wired, and the Guardian. She is a W. T. Grant Foundation scholar. She received her PhD in computer science from Stanford University in 2018.","session",homepage
3,"static/images/speakers/chrismre_headshot_lowres.jpg","Associate Professor","Prof. Christopher Re","Department of Computer Science at Stanford University","Talk Title - To be added",Talk Abstract - To be added,"Speaker Bio - to be added","session","https://cs.stanford.edu/~chrismre/"
4,"static/images/speakers/percy3.jpeg","Associate Professor","Prof. Percy Liang","Department of Computer Science at Stanford University",Benchmarking in the Era of Foundation Models,"Benchmarks orient AI.  They have played a vital role in both the direction and velocity of how the technology develops.  Traditionally, benchmarks have focused on particular tasks (e.g., object recognition or question answering).  But with the rise of foundation models such as GPT-4, the scope of benchmarking has vastly expanded given their general-purpose nature.  In this talk, we describe some of our efforts to benchmark foundation models, including Holistic Evaluation of Language Models (HELM), interactive and multimodal extensions, and evaluation of generative search engines such as Bing Chat.  Benchmarking shines a spotlight on the capabilities and limitations of foundation models, serving as a faithful guide for researchers, application developers, and policymakers."," Percy Liang is an Associate Professor of Computer Science at Stanford University (B.S. from MIT, 2004; Ph.D. from UC Berkeley, 2011) and the director of the Center for Research on Foundation Models and a co-founder of Together AI. His research spans many topics in machine learning and natural language processing, including robustness, interpretability, semantics, and reasoning. He is also a strong proponent of reproducibility through the creation of CodaLab Worksheets. His awards include the Presidential Early Career Award for Scientists and Engineers (2019), IJCAI Computers and Thought Award (2016), an NSF CAREER Award (2016), a Sloan Research Fellowship (2015), a Microsoft Research Faculty Fellowship (2014), and multiple paper awards at ACL, EMNLP, ICML, and COLT.","session","https://cs.stanford.edu/~pliang/"

